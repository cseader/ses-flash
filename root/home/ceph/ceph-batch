#!/bin/bash
#
# ceph-batch
# 
# author cs@suse.com
#
#####################

# TODO:
# Need to setup nodes list in xml or yaml format to be read by this script
# Need to have the list used to setup /etc/hosts on all nodes
#

#
# Global variables
nodes="node1 node2 node3"

# Function discovering OSD's (available disks that are not /)
# Nodes Array
anodes=($nodes)

discover_osds () {
for i in "${anodes[@]}"; do
  #determine what roots disk is on remote node in cluster
  rootdisk=$(ssh -q $i mount | grep "on \/ " | awk {'print $1'} | sed 's/.....//;s/.$//g')
  #determine all disks available to remote node in cluster
  alldisks=$(ssh -q $i sudo parted -l | grep "Disk \/" | awk {'print $2'} | sed 's/.....//;s/.$//g' | xargs)
  #expand all disks and strip roots disk and white space
  osds=$(echo "$alldisks" | sed 's/'$rootdisk'//g;s/^[ \t]*//')
    #Put the disk and node together in usable ceph-deploy format; result is $nosds
    for d in $osds; do
      #echo $rootdisk
      #echo $alldisks
      nosds=$(echo $i:$d)
      echo $nosds
    done
done
}

# Nodes and discovered OSD's Array format: node1:sdb
aosds=(`discover_osds | xargs`)

# ceph-deploy install
ceph-deploy install $nodes

# ceph-deploy new
ceph-deploy new $nodes

# ceph-deploy mon create-initial
# Create the initial monitor service on already created monitor nodes
ceph-deploy mon create-initial

# prompt user to continue
#echo "The system has discovered these osds: "`discover_osds`""
#echo "If these are correct and you would like to proceed then type 'yes':"

#read -s yes

# clean disks
for i in "${aosds[@]}"; do
    ceph-deploy disk zap $i
done

# ceph-deploy prepare disks
for i in "${aosds[@]}"; do
    ceph-deploy --overwrite-conf osd prepare $i
done 

# ceph-deploy activate disks
for i in "${aosds[@]}"; do
   #strip trailing white space from $i
   osd=$(echo "$i" | sed 's/\s*$//g')
   ceph-deploy osd activate "$osd"1
done
